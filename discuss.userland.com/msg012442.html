<html>	<head>		<title>Re: SalonHerringWiredFool.Com</title>		</head>	<body>		<blockquote><blockquote>			<b>Archive of UserLand's first discussion group, started October 5, 1998.</b><hr>			<h2>Re: SalonHerringWiredFool.Com</h2>			<table cellpadding="0" cellspacing="5">				<tr><td><b>Author:</b></td><td>Paul Snively</td></tr>				<tr><td><b>Posted:</b></td><td>10/28/1999; 12:39:22 AM</td></tr>				<tr><td><b>Topic:</b></td><td><a href="msg012384.html">SalonHerringWiredFool.Com</a></td></tr>				<tr><td><b>Msg #:</b></td><td>12442 (In response to <a href="msg012419.html">12419</a>)</td></tr>				<tr><td><b>Prev/Next:</b></td><td><a href="msg012441.html">12441</a> / <a href="msg012443.html">12443</a></td></tr>				</table>			<br>Dru Oja Jay wrote:<p>

<I>The difference comes in the fact that Amazon.com can handle several million hits a day, not to mention transactions on that scale. The volume is the hard part, not the concept.</I><p>

The volume isn't hard these days either, although it used to be, back in, say, 1995 or so.<p>

The lessons learned since then:<p>

1) You *cannot* get away with forking a new process on every
   connection.<p>

2) You *cannot* get away with opening a new connection to the
   database on every connection.<p>

3) Your database's working set had bloody well better fit in the
   available RAM of the database server.<p>

Adhere to these lessons and you'll find there is no scalability problem on the web. The truly hard part, again, is maintenance: how to keep a site operational 24/7.
			<br><br>			<br><br><hr>This page was archived on 6/13/2001; 4:53:14 PM.<br><br>&copy; Copyright 1998-2001 <a href="http://www.userland.com/">UserLand Software</a>, Inc.			</blockquote></blockquote>		</body>	</html>